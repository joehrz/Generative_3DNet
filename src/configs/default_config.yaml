# ===================================================================
# ==         Default Configuration for BI-Net Project              ==
# ===================================================================
# This file centralizes all parameters for the project, making
# experiments reproducible and easy to manage.

# ==================================
# ==        Data Settings         ==
# ==================================
data:
  # --- Active Data Paths (Sorghum Plants) ---
  raw_dir: "data/Sorghum_Plants_Point_Cloud_Data/raw"
  processed_dir: "data/Sorghum_Plants_Point_Cloud_Data/processed"
  splits_dir: "data/Sorghum_Plants_Point_Cloud_Data/splits"
  
  # --- Commented Out Data Paths (ShapeNet Example) ---
  # raw_dir: "shape_net_data/chairs_03001627"
  # processed_dir: "shape_net_data/processed"
  # splits_dir: "shape_net_data/splits"

  # Ratios for splitting the dataset into train, validation, and test sets.
  # This MUST sum to 1.0.
  split_ratios: [0.8, 0.1, 0.1]

  # Final subdirectories used by the DataLoader.
  splits:
    train_dir: "data/Sorghum_Plants_Point_Cloud_Data/splits/train"
    val_dir: "data/Sorghum_Plants_Point_Cloud_Data/splits/val"
    test_dir: "data/Sorghum_Plants_Point_Cloud_Data/splits/test"
    # train_dir: "shape_net_data/splits/train"
    # val_dir: "shape_net_data/splits/val"
    # test_dir: "shape_net_data/splits/test"

# ==================================
# ==   Preprocessing Settings     ==
# ==================================
preprocessing:
  # Voxel size for downsampling. A larger value means more aggressive downsampling.
  voxel_size: 0.02
  # Target number of points for each point cloud after preprocessing.
  num_points: 2048
  # Use Farthest Point Sampling (FPS) for downsampling to num_points.
  use_fps: true
  # If true, skips the voxel_downsampling step entirely.
  skip_downsample: false

# ==================================
# ==      Model Architecture      ==
# ==================================
model:
  # Directory to save model checkpoints
  save_dir: "models/checkpoints"
  # Latent dimension of the autoencoder
  latent_dim: 128
  # Weight for the gradient penalty in WGAN-GP
  lambda_gp: 10.0
  # Weight for the uniformity loss (NNME) on the generator
  lambda_nnme: 1.0 #0.1
  # Number of neighbors for support in TreeGCN
  support: 10
  
  # --- Generator Architecture (Set to what paper has) ---
  features_g: [128, 256, 256, 256, 128, 128, 128, 3]
  degrees: [1, 2, 2, 2, 2, 2, 64] # Product is 2048

# ==================================
# ==      Training Settings       ==
# ==================================
training:
  # Compute device: 'cuda' or 'cpu'
  device: "cuda"
  # Number of training epochs
  epochs: 10
  # Batch size for training and evaluation
  batch_size: 12
  # Number of epochs to train only the autoencoder before starting GAN training
  warmup_epochs: 10
  
  # --- Learning Rates & Optimizer ---
  lr_enc: 0.0002
  lr_dec: 0.0002
  lr_disc: 0.0002
  betas: [0.0, 0.999]
  
  # --- Optional Learning Rate Scheduler ---
  scheduler_step_size: 20
  scheduler_gamma: 0.5
  
  # --- GAN Training Ratios ---
  d_iters: 1
  g_iters: 1
  
  # --- Loss Weights ---
  lambda_rec: 1.0
  
  # EMD calculation parameters
  emd_eps: 0.002
  emd_iters: 50
  
  # --- Logging and Validation ---
  log_interval: 50
  val_interval: 5
  tensorboard_mesh_log_interval: 500

  # --- Data Augmentation Flags ---
  augment_rotate: True
  augment_flip: True
  augment_scale: True
  augment_min_scale: 0.9
  augment_max_scale: 1.1
  augment_noise_std: 0.005
  augment_jitter_sigma: 0.01
  augment_jitter_clip: 0.02

# ==================================
# ==    Generation Settings       ==
# ==================================

  # Number of shapes to generate when running with --generate
  sample_count: 8