{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- BI-Net exploration in a Jupyter Notebook ---\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # points to my_project\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Double-check\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n",
    "print(\"Contents:\", os.listdir(PROJECT_ROOT))\n",
    "\n",
    "# Now import the function\n",
    "from src.models.bi_net import BiNet\n",
    "\n",
    "# Import dataset class\n",
    "from src.dataset.pc_dataset import PointCloudDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 2) Define Model Hyperparameters\n",
    "##############################################\n",
    "\n",
    "# Example settings:\n",
    "batch_size = 1        # how many point clouds in a batch\n",
    "latent_dim = 96       # dimension of the latent code\n",
    "features_g = [latent_dim, 128, 128, 64, 64, 32, 3]  # for decoder/generator layers\n",
    "degrees    = [4, 4, 4, 4, 4, 2]   # expansion degrees in the TreeGCN\n",
    "enc_disc_feat = [3, 64, 128, 256, 512] # for encoder/discriminator\n",
    "support = 10          # support factor in the TreeGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the BI-Net\n",
    "binet = BiNet(\n",
    "    batch_size=batch_size,\n",
    "    features_g=features_g,\n",
    "    degrees=degrees,\n",
    "    enc_disc_feat=enc_disc_feat,\n",
    "    latent_dim=latent_dim,\n",
    "    support=support\n",
    ")\n",
    "\n",
    "# Move to GPU if available:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "binet.to(device)\n",
    "binet.eval()\n",
    "\n",
    "print(\"BI-Net model created and set to eval mode.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 3) Forward Pass (Auto-Encoder direction)\n",
    "##############################################\n",
    "# Feed random data shaped (batch_size, N_points, 3)\n",
    "dummy_input = torch.randn(batch_size, 512, 3).to(device)  # e.g. 512 points per cloud\n",
    "latent_code = binet.encode(dummy_input)   # Encode\n",
    "print(\"Encoded latent shape:\", latent_code.shape)\n",
    "\n",
    "rec_points = binet.decode(latent_code)    # Decode\n",
    "print(\"Reconstructed points shape:\", rec_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 4) Reverse Pass (GAN direction)\n",
    "##############################################\n",
    "# Generate from random noise\n",
    "z = torch.randn(batch_size, latent_dim).to(device)\n",
    "fake_points = binet.generate(z)\n",
    "print(\"Generated (fake) points shape:\", fake_points.shape)\n",
    "\n",
    "# Discriminate real vs. fake\n",
    "disc_real = binet.discriminate(dummy_input)\n",
    "disc_fake = binet.discriminate(fake_points)\n",
    "print(\"Discriminator score for real shape:\", disc_real.shape)\n",
    "print(\"Discriminator score for fake shape:\", disc_fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 5) Test on Another Random Point Cloud\n",
    "##############################################\n",
    "# Suppose we have a new random input shaped (1, 1024, 3) simulating an external \"random\" point cloud\n",
    "random_pc = torch.randn(1, 1024, 3).to(device)\n",
    "print(\"\\nTesting BI-Net on another random point cloud of shape:\", random_pc.shape)\n",
    "\n",
    "# AE pass on the second random cloud\n",
    "latent_code_2 = binet.encode(random_pc)\n",
    "rec_points_2 = binet.decode(latent_code_2)\n",
    "\n",
    "print(\"Encoded shape (2nd random input):\", latent_code_2.shape)\n",
    "print(\"Reconstructed shape (2nd random input):\", rec_points_2.shape)\n",
    "\n",
    "# Optionally, discriminate it as \"real\"\n",
    "disc_real_2 = binet.discriminate(random_pc)\n",
    "print(\"Discriminator output on 2nd random input:\", disc_real_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# 6) Final Summary\n",
    "##############################################\n",
    "print(\"\\n--- BI-Net Exploration Summary ---\")\n",
    "print(\"AE direction => Encoded shape (1st input):\", latent_code.shape, \n",
    "      \"| Reconstructed shape (1st input):\", rec_points.shape)\n",
    "print(\"GAN direction => Fake shape:\", fake_points.shape,\n",
    "      \"| Disc score shapes (real, fake):\", disc_real.shape, disc_fake.shape)\n",
    "print(\"2nd random input => Encoded shape:\", latent_code_2.shape, \n",
    "      \"| Reconstructed shape:\", rec_points_2.shape,\n",
    "      \"| Disc output (as real):\", disc_real_2.shape)\n",
    "print(\"Everything is running. Customize or extend for training, debugging, or actual data loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# 1) Create the dataset object\n",
    "##########################################\n",
    "data_root = os.path.join(PROJECT_ROOT, \"data\")\n",
    "train_root = os.path.join(PROJECT_ROOT, \"data\\\\splits\\\\train\")\n",
    "\n",
    "\n",
    "dataset = PointCloudDataset(root=data_root, split=\"processed\", transform=None)\n",
    "\n",
    "print(f\"Loaded dataset with {len(dataset)} samples (train split).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "##########################################\n",
    "# 7) Pick a random index & load one point cloud data/npz\n",
    "##########################################\n",
    "if len(dataset) == 0:\n",
    "    print(\"Dataset is empty! Please check your dataset folder.\")\n",
    "else:\n",
    "    rand_idx = random.randint(0, len(dataset) - 1)\n",
    "    pc_data = dataset[rand_idx]  # shape => (N, 3) Torch Tensor\n",
    "    print(f\"Random index: {rand_idx}, pc_data shape: {pc_data.shape}\")\n",
    "\n",
    "    # Add batch dimension => (1, N, 3)\n",
    "    pc_data = pc_data.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# 4) Send point cloud to device & run AE pass\n",
    "##########################################\n",
    "pc_data = pc_data.to(device)  # shape => (1, N, 3)\n",
    "with torch.no_grad():\n",
    "    latent = binet.encode(pc_data)            # shape => (1, latent_dim)\n",
    "    rec_points = binet.decode(latent)         # shape => (1, N, 3)\n",
    "\n",
    "print(f\"Latent code shape: {latent.shape}\")\n",
    "print(f\"Reconstructed points shape: {rec_points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# 5) Discriminator on that single real cloud\n",
    "##########################################\n",
    "disc_output = binet.discriminate(pc_data)     # shape => (1, 1)\n",
    "print(f\"Discriminator output on real cloud: {disc_output}\")\n",
    "\n",
    "##########################################\n",
    "# 6) Interpret the Results\n",
    "##########################################\n",
    "print(\"\\n--- Single Point Cloud Exploration ---\")\n",
    "print(f\"Random index: {rand_idx}, Original shape: {pc_data.shape}\")\n",
    "print(f\"Latent code shape: {latent.shape}, Reconstructed shape: {rec_points.shape}\")\n",
    "print(f\"Discriminator output on real: {disc_output.shape} => {disc_output}\")\n",
    "print(\"Done. If your model is untrained, reconstruction may be random. If trained, it should reflect learned geometry.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "# rec_points: shape => (1, N, 3), e.g. (1, 2048, 3)\n",
    "rec_np = rec_points[0].cpu().numpy()  # => shape (2048, 3)\n",
    "\n",
    "# Convert rec_np to Open3D point cloud\n",
    "pcd_recon = o3d.geometry.PointCloud()\n",
    "pcd_recon.points = o3d.utility.Vector3dVector(rec_np)\n",
    "\n",
    "# Visualize\n",
    "o3d.visualization.draw_geometries([pcd_recon])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
